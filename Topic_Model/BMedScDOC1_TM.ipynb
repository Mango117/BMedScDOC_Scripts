{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f29a5b6-c248-49c7-b1d4-24733e373315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "#topic model using NMF\n",
    "import pandas as pd\n",
    "#import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import sys\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95afb6f2-03ff-4740-ad90-fd4caef32987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    path = \"/Users/manojarachige/Documents/Coding/BMedScDOC1/BMedScDOC2021/Topic_Model/separated_pdfs\"\n",
    "    #txt_lst is a list of all the txt files in our path folder\n",
    "    # make a csv file headers: PMID, Text, len of text\n",
    "    # NMF\n",
    "    make_csv(path)\n",
    "    \n",
    "    docs=pd.read_csv('corpus.csv', encoding = 'unicode_escape', encoding_errors = 'ignore', engine ='c')\n",
    "    # use tfidf by removing tokens that don't appear in at least 50 documents\n",
    "    #for youtube comments change to 2\n",
    "    vect = TfidfVectorizer(min_df=2, stop_words='english')\n",
    "    # Fit and transform\n",
    "    X = vect.fit_transform(docs.Text)\n",
    "    \n",
    "    # Create an NMF instance: model\n",
    "    # the empircal 10 components will be the topics\n",
    "    model = NMF(n_components=10, random_state=5)\n",
    "    # Fit the model to TF-IDF\n",
    "    model.fit(X)\n",
    "    # Transform the TF-IDF: nmf_features\n",
    "    nmf_features = model.transform(X)\n",
    "    X.shape\n",
    "    nmf_features.shape\n",
    "    model.components_.shape\n",
    "    components_df = pd.DataFrame(model.components_, columns=vect.get_feature_names())\n",
    "    components_df\n",
    "    \n",
    "    for topic in range(components_df.shape[0]):\n",
    "        tmp = components_df.iloc[topic]\n",
    "        print(f'For topic {topic+1} the words with the highest value are:')\n",
    "        print(tmp.nlargest(10))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf41edc0-5b75-4c7b-b233-308933f0b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a corpus of texts from folder and separate its .txt files\n",
    "def get_corpus(basepath):\n",
    "    lst = os.listdir(basepath)\n",
    "    lst.sort()\n",
    "    newlst = []\n",
    "    for file in lst:\n",
    "        check = file\n",
    "        path = os.path.abspath(check)\n",
    "        ext = os.path.splitext(path)[-1].lower()\n",
    "        if ext == \".txt\":\n",
    "            newlst.append(check)\n",
    "    return newlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8115c980-bb26-4cfe-9899-67a2995d5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(folder_path):\n",
    "    txt_lst = get_corpus(folder_path) #list\n",
    "    \n",
    "    headers = [\"PMID\", \"Text\"]\n",
    "    PMID = txt_lst\n",
    "    Text = []\n",
    "    Length = []\n",
    "    \n",
    "    with open('corpus.csv', 'w', encoding='UTF8', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)\n",
    "        \n",
    "        for i in range(len(txt_lst)):\n",
    "            filepath = folder_path + \"/\" + txt_lst[i]\n",
    "            with open(filepath, 'r') as contents:\n",
    "                string = contents.read()\n",
    "                string.replace(\"\\n\", \" \")\n",
    "                string.encode('unicode_escape')\n",
    "                data = [txt_lst[i], string]\n",
    "                writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec043a1-7f91-40b8-9a3c-5f8c432c30dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manojarachige/opt/miniconda3/envs/BMedScDOC1/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For topic 1 the words with the highest value are:\n",
      "https          1.419333\n",
      "org            1.350579\n",
      "doi            1.337037\n",
      "10             1.118430\n",
      "frontiersin    1.041300\n",
      "1016           0.726164\n",
      "www            0.517654\n",
      "journals       0.369604\n",
      "al             0.369555\n",
      "et             0.354318\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "\n",
      "For topic 2 the words with the highest value are:\n",
      "ï¼    2.838632\n",
      "ªã    0.637662\n",
      "³ã    0.403336\n",
      "çµ    0.326233\n",
      "ä½    0.322822\n",
      "èª    0.257247\n",
      "ä¾    0.253023\n",
      "å¾    0.252800\n",
      "åº    0.224498\n",
      "¾ã    0.212123\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "\n",
      "For topic 3 the words with the highest value are:\n",
      "encephalitis    0.383634\n",
      "case            0.361063\n",
      "anti            0.313979\n",
      "patient         0.313144\n",
      "csf             0.288884\n",
      "day             0.244549\n",
      "mri             0.236374\n",
      "mg              0.235719\n",
      "nmdar           0.234709\n",
      "patients        0.231289\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "\n",
      "For topic 4 the words with the highest value are:\n",
      "covid          1.532097\n",
      "2020           0.771677\n",
      "sars           0.625461\n",
      "cov            0.601313\n",
      "19             0.474598\n",
      "coronavirus    0.376048\n",
      "https          0.247488\n",
      "infection      0.225290\n",
      "patients       0.178183\n",
      "respiratory    0.164654\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "\n",
      "For topic 5 the words with the highest value are:\n",
      "ncbi         0.745012\n",
      "nlm          0.742840\n",
      "dopt         0.719469\n",
      "pubmed       0.676429\n",
      "nih          0.644963\n",
      "gov          0.617042\n",
      "http         0.458000\n",
      "entrez       0.404334\n",
      "list_uids    0.404334\n",
      "fcgi         0.398698\n",
      "Name: 4, dtype: float64\n",
      "\n",
      "\n",
      "For topic 6 the words with the highest value are:\n",
      "stroke        1.774369\n",
      "patients      0.559564\n",
      "ischemic      0.279416\n",
      "infarction    0.273912\n",
      "artery        0.248052\n",
      "nihss         0.202912\n",
      "acute         0.197246\n",
      "cerebral      0.187066\n",
      "occlusion     0.182037\n",
      "onset         0.174405\n",
      "Name: 5, dtype: float64\n",
      "\n",
      "\n",
      "For topic 7 the words with the highest value are:\n",
      "mcs           1.080874\n",
      "uws           0.745072\n",
      "patients      0.692066\n",
      "doc           0.595053\n",
      "vs            0.552814\n",
      "crs           0.444660\n",
      "brain         0.395996\n",
      "vegetative    0.335798\n",
      "state         0.320615\n",
      "injury        0.314150\n",
      "Name: 6, dtype: float64\n",
      "\n",
      "\n",
      "For topic 8 the words with the highest value are:\n",
      "patients    0.714832\n",
      "study       0.326792\n",
      "care        0.231487\n",
      "health      0.225872\n",
      "injury      0.207927\n",
      "syncope     0.204605\n",
      "delirium    0.186452\n",
      "risk        0.182281\n",
      "group       0.181828\n",
      "score       0.175944\n",
      "Name: 7, dtype: float64\n",
      "\n",
      "\n",
      "For topic 9 the words with the highest value are:\n",
      "brain           0.411317\n",
      "connectivity    0.402408\n",
      "et              0.340045\n",
      "al              0.336590\n",
      "network         0.308864\n",
      "cortex          0.287311\n",
      "activity        0.284120\n",
      "eeg             0.272029\n",
      "functional      0.259488\n",
      "fmri            0.234799\n",
      "Name: 8, dtype: float64\n",
      "\n",
      "\n",
      "For topic 10 the words with the highest value are:\n",
      "en     0.581532\n",
      "la     0.566982\n",
      "que    0.369338\n",
      "er     0.366000\n",
      "se     0.363123\n",
      "ti     0.359783\n",
      "el     0.346992\n",
      "es     0.336289\n",
      "th     0.312556\n",
      "io     0.276998\n",
      "Name: 9, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1602e58-61b9-4621-8223-4b810877f933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
